{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy==2.2.3 pandas==2.2.3 matplotlib==3.10.0 seaborn==0.13.2 scipy==1.15.2 statsmodels==0.14.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aL7GieePuIq_"
   },
   "source": [
    "**Statistics** plays a crucial role in machine learning by providing the theoretical foundation and practical tools necessary for building robust and efficient models. It can also help in the preprocessing steps in machine learning, like gaining a better understanding of the data or feature engineering\n",
    "\n",
    "**Probability** can help in understanding and quantifying the uncertainty associated with the predictions of a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upzJhEU6W5fQ"
   },
   "source": [
    "# Descriptive Statistics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDecz9sEsuup"
   },
   "source": [
    "Descriptive statistics help summarize and organize data so that it can be easily understood. These statistics allow us to analyze data distributions and identify key characteristics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ifix2N2qtCJp",
    "outputId": "346530a9-2bcb-4936-ae62-59a54a818029"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Hours_Worked_Per_Week</th>\n",
       "      <th>Years_of_Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>25903.305196</td>\n",
       "      <td>56</td>\n",
       "      <td>2.325089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>53051.954538</td>\n",
       "      <td>23</td>\n",
       "      <td>7.712978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>38654.738821</td>\n",
       "      <td>23</td>\n",
       "      <td>0.886359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>28666.194356</td>\n",
       "      <td>39</td>\n",
       "      <td>1.522041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>40301.406736</td>\n",
       "      <td>29</td>\n",
       "      <td>2.528741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        Salary  Hours_Worked_Per_Week  Years_of_Experience\n",
       "0   56  25903.305196                     56             2.325089\n",
       "1   69  53051.954538                     23             7.712978\n",
       "2   46  38654.738821                     23             0.886359\n",
       "3   32  28666.194356                     39             1.522041\n",
       "4   60  40301.406736                     29             2.528741"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = 1000\n",
    "\n",
    "data = {\n",
    "    'Age': np.random.randint(18, 70, n),\n",
    "    'Salary': np.abs(np.random.normal(50000, 15000, n)),\n",
    "    'Hours_Worked_Per_Week': np.random.randint(20, 60, n),\n",
    "    'Years_of_Experience': np.random.lognormal(mean=1, sigma=0.7, size=n)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRXyrwxcmgTl"
   },
   "source": [
    "## Measures of central tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSEepecIvHI2"
   },
   "source": [
    "These measures describe the center or typical value of a dataset: mean, median, mode..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuQs2gKsvRcx"
   },
   "source": [
    "## Measures of dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7Rl5vqSFi2p"
   },
   "source": [
    "These measures describe how spread out the data is: range, variance, standard deviation, quantiles, interquantile range..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GE_1_n3DvVsU"
   },
   "source": [
    "The **variance** measures how far each data point in a dataset is from the mean. It is defined as:\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\bar{x})^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x_i$ are the individual data points,\n",
    "- $\\bar{x}$ is the mean of the data points,\n",
    "- $N$ is the total number of data points in the population,\n",
    "\n",
    "The **standard deviation** is the square root of the variance. It is useful because it is expressed in the same units as the original data, making it easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGSdu6rHFg-C"
   },
   "source": [
    "**Quantiles** divide a probability distribution into continuous intervals with equal probabilities. There is one fewer quantile than the number of groups created. Common quantiles have special names, such as quartiles (four groups), deciles (ten groups), and percentiles (100 groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "517b_uCVF0SC"
   },
   "source": [
    "The *z-score* (or standard error) is the number of standard deviations by which the value of a data point is above or below the mean value. It is calculated by subtracting the mean from an individual observation and then dividing the difference by the standard deviation:\n",
    "\n",
    "$$\n",
    "Z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "The process of converting a raw score into a standard score is called standardizing: it is a type of normalization that works well when the data is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQQMA11svDgK"
   },
   "source": [
    "## Frequency Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsMWccdDqVjE",
    "outputId": "60e7f301-fb74-4272-e0a7-7160963e1dfe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "bKpoO8DBqkpt",
    "outputId": "5a503c8a-78e4-492d-b4cd-b71081882f93"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NagjuKboJQR7"
   },
   "source": [
    "**Skewness** measures the asymmetry of a probability distribution.\n",
    "- Negative skew: the distribution is left-skewed/left-tailed\n",
    "- Positive skew: the distribution is right-skewed/right-tailed\n",
    "\n",
    "Skewness indicates the direction and relative magnitude of a distribution's deviation from the normal distribution (this is important because many statistical methods assume a normal distribution).\n",
    "\n",
    "**Kurtosis** measures the \"tailedness\" of a probability distribution, indicating whether data has more or fewer extreme values (outliers) than a normal distribution.\n",
    "\n",
    "- If the kurtosis is positive, the distribution is *leptokurtic* (heavy tails, more extreme values).\n",
    "- If the kurtosis is negative the distribution is *platykurtic* (light tails, fewer extreme values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7Gf4bb9JPPc",
    "outputId": "9404bde8-cf7f-4b8c-e8f3-0e8052d7978d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOVuxVeZPuHD"
   },
   "source": [
    "When the distribution is right-skewed, the logarithmic trasformation can be useful to make it more symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "mXwxap1dVgo_",
    "outputId": "40cb6b11-b59a-4cd5-bed7-8300c2cfcf4f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlpFuBvFvvCr"
   },
   "source": [
    "# Introduction to Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ0jLK_D-Zrb"
   },
   "source": [
    "Probability is a branch of mathematics that measures the likelihood or chance of an event occurring. It quantifies uncertainty and is expressed as a number between 0 and 1.\n",
    "\n",
    "Key Concepts:\n",
    "- **Experiment**: A process or action that produces outcomes, such as rolling a die or flipping a coin. Random (with more than one possible outcome, otherwise deterministic) experiments are often conducted repeatedly (ex. rolling a die 2 times), in which case the individual repetitions are called trials.\n",
    "- **Outcome**: A possible result of an experiment, e.g., rolling a 3 twice on a die.\n",
    "- **Sample Space**: The set of all possible outcomes of an experiment. For example, for rolling a six-sided die once: {1, 2, 3, 4, 5, 6}; for rolling a six-sided die twice there are 36 possible outcomes: {(1, 1), (1, 2), ...}\n",
    "- **Event**: A subset of the sample space, representing one or more outcomes. For instance, when rolling a six-sided die once, {2, 4, 6} is the event \"rolling an even number\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mncxsHOMA8rw"
   },
   "source": [
    "The **theoretical probability** of an event $A$ occurring is given by:  \n",
    "\n",
    "$$\n",
    "P(A) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total number of possible outcomes}}\n",
    "$$\n",
    "\n",
    "The **empirical probability** is calculated from observed data in the context of real-world experimentsa and data:  \n",
    "\n",
    "$$\n",
    "P(A) = \\frac{\\text{Number of times A occurs}}{\\text{Total number of trials}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLMU6_zev1fh",
    "outputId": "8fa00f9d-f623-4aec-95dc-6f82bfe689c3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hLNulCS5nui",
    "outputId": "2f53c005-ab4c-4183-a077-58e24963bdbf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-9BEp5wHYH5"
   },
   "source": [
    "## Probability rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bff638hDJrYx"
   },
   "source": [
    "- The probability of any event lies between 0 (impossible event) and 1 (certain event)\n",
    "- The probability of an event not occurring (its complement) is: $$\n",
    "P(A^c) = 1 - P(A)\n",
    "$$  \n",
    "\n",
    "  This is because the sum of all possible outcomes must be equal to 1.\n",
    "\n",
    "- The probability of either event $A$ or event $B$ occurring (union) is: $$\n",
    "P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n",
    "$$\n",
    "\n",
    "  If $A$ and $B$ are mutually exclusive (they cannot happen together), then:  \n",
    "\n",
    "$$\n",
    "P(A \\cup B) = P(A) + P(B)\n",
    "$$\n",
    "\n",
    "- The probability of both event $A$ or event $B$ occurring (intersection) is: $$\n",
    "P(A \\cap B) = P(A) \\times P(B)\n",
    "$$\n",
    "\n",
    "  for **independent events** (one does not affect the other) and $$\n",
    "P(A \\cap B) = P(A) \\times P(B | A)\n",
    "$$\n",
    "  for **dependent events** (one affects the other).\n",
    "\n",
    "  This means that if $P(B) = P(B | A)$ events $A$ and $B$ are independent, i.e. the occurrence of $B$ does not affect the probability of $A$ and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sT75lw8jwWQu",
    "outputId": "186f4c4e-e519-429d-8f47-28a3bfb0f303"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxLULJG7RaaQ"
   },
   "source": [
    "## Conditional probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "se0UEZ7UMXBp"
   },
   "source": [
    "**Conditional probability** measures the probability of an event occurring, given that another event is already known (by assumption, evidence etc.) to have occurred: $$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "The **Law of total probability** allows us to calculate the probability of an event $A$ based on its conditional probabilities, given a set of mutually exclusive and exhaustive (at least one must occur) events $B_1, B_2, ..., B_n$.\n",
    "\n",
    "$$P(A) = P(A|B_1)P(B_1)+P(A|B_2)P(B_2)+\\cdots+P(A|B_n)P(B_n)=\\sum_{i} P(A | B_i)P(B_i)$$\n",
    "\n",
    "It is particularly useful when direct computation of an event's probability is challenging.\n",
    "\n",
    "**Bayes' Theorem** is a mathematical formula used to update the probability of an event based on new evidence. It allows us to calculate conditional probabilities:\n",
    "\n",
    "$$P(A|B)=\\frac{P(B|A)\\cdot P(A)}{P(B)}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lnau13bnwuDf",
    "outputId": "9d7a9a5b-a11d-4bce-8fda-c28330fd6e42"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWCadetRzULk"
   },
   "source": [
    "# Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoO7qBQ4Z70c"
   },
   "source": [
    "A probability distribution is the mathematical function that describes the probabilities of occurrence of possible outcomes of an experiment.\n",
    "\n",
    "A **discrete** probability distribution is applicable to scenarios where the set of possible outcomes is discrete (e.g. a coin toss, a roll of a die); in this case the discrete probability distribution is known as probability mass function. On the other hand, **continuous** probability distributions are applicable to scenarios where the set of possible outcomes can take on values in a continuous range (e.g. real numbers), such as the temperature on a given day. In the continuous case, probabilities are described by a probability density function, and the probability distribution is by definition the integral of the probability density function.\n",
    "\n",
    "The **expected value** is a concept in probability theory and statistics that represents the average outcome of a random variable, weighted by the probability of those outcomes. Therefore, it is a weighted average of all possible outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1220lN4OaJv2"
   },
   "source": [
    "The **Bernoulli** distribution is the discrete probability distribution of a random variable with a boolean outcome, i.e. which takes the value \"success\" with probability $p$ and the value \"failure\" with probability $1-p$ (for example, a coin toss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "xq8wY5pwgBQE",
    "outputId": "0ed1abcd-c45c-4608-aa84-16cd1c90b98d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcS0WNL-dPdz"
   },
   "source": [
    "The **binomial** distribution is the discrete probability distribution of the number of successes in a sequence of independent trials, where the result of each trial can be either “success” or “failure”. The Bernoulli is a special case of the Binomial distribution where the number of trials is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "1eUMXp5hgKJi",
    "outputId": "1dc7f1ab-2334-43d6-a1af-34e7feb8cb57"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhOuEED9ebFF"
   },
   "source": [
    "The **Poisson** probability distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time, if these events occur with a known constant mean rate and independently of the time since the last event.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "ZC41ZHlxgRLw",
    "outputId": "7c90f6fc-7793-4baf-dcb8-5dae35e3b5c6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d-E_kFLSftD"
   },
   "source": [
    "The **discrete uniform** distribution is a symmetric probability distribution wherein each of the outcome values are equally likely to be observed. This means that every one of the n outcome values has equal probability 1/n.\n",
    "\n",
    "The **continuous uniform** distribution is a symmetric probability distribution that describes an experiment where there is an arbitrary outcome that lies between certain bounds. All intervals of the same length are equally probable. Therefore, all outcomes are equally likely within a specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "QtB3eD9EgsIZ",
    "outputId": "fbd6559a-db10-4a4e-97ec-4021ef6935bd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJSIAlHeXnl1"
   },
   "source": [
    "The **exponential** distribution is the continuous probability distribution of the distance between events in a Poisson process, i.e. events that occur continuously and independently at a constant average rate (the rate is the probability per unit time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "T1XojepJX6Dd",
    "outputId": "27f04b98-b44b-44bf-ec48-0ffc4f3dce0d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_k0Zz1hnl76"
   },
   "source": [
    "The **normal** distribution is a continuous probability symmetric distribution, characterized by its bell-shaped curve, where most of the values cluster around the mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "KZ1yhnoIgS_j",
    "outputId": "640b4df3-1ec6-4206-8e87-d4688c815df1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEsRFmWJjocj"
   },
   "source": [
    "# Inferential Statistics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3z_dMvQgj8ny"
   },
   "source": [
    "**Inferential statistical** infers properties of a population, for example by testing hypotheses and estimating population parameters (e.g. the mean). It is assumed that the observed data set is sampled from a larger population.\n",
    "\n",
    "Descriptive statistics on the other hand is only concerned with properties of the observed data, and it does not assume that the data come from a larger population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSV2BIxGxXG8"
   },
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4yKMWPshZZ7"
   },
   "source": [
    "A **statistical population** refers to a set of similar items or events which is of interest for some question or experiment. It can be real (e.g. male US citizens) or hypothetical (e.g. the set of all possible hands in a game of poker).\n",
    "\n",
    "**Sampling** is the selection of a subset (statistical sample) from a statistical population in order to estimate characteristics about the whole population.\n",
    "\n",
    "The goal is to gather a representative sample, i.e. one that is able to reflect the whole population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "e566af0Ij52B",
    "outputId": "5b02900b-bd79-46f5-f0c9-f913ec8532ae"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9_Ni1RzzhPx"
   },
   "source": [
    "## Law of Large Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wT1iey0tnGwW"
   },
   "source": [
    "The law of large numbers states that given a large sample of independent and identically distributed values, the sample mean converges to the true mean (expected value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "gniJaYkBP6sv",
    "outputId": "643537c8-5cdb-4d26-c5d4-7705b5e70d58"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yractLEvz7Vy"
   },
   "source": [
    "## Monte Carlo methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX3GdSBUmtWT"
   },
   "source": [
    "Monte Carlo methods are a class of computational algorithms that rely on repeated random sampling to obtain numerical results. They are a good example of the Law of large numbers, because the larger the number of repetitions, the better the approximation tends to be. They are often implemented using computer simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "b0U_eMODcGC7",
    "outputId": "5f61edd9-a2c9-4ea0-bc62-b39ff4299a61"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKq3V9n2euO8"
   },
   "source": [
    "## Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INlLWxHAeuO8"
   },
   "source": [
    "The **Central Limit Theorem** (CLT) states that the distribution of sample means will approximate a normal distribution as the sample size increases (usually 30 is enough), regardless of the original population's distribution shape.\n",
    "\n",
    "This means that if we would take many random samples of size $n$ from any population and compute their means, the distribution of those means will be:\n",
    "approximately normal, centered around the true population mean $\\mu$ and with a standard deviation given by $\\frac{\\sigma}{\\sqrt{n}}$, where $\\sigma$ is the standard deviation of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "7cH5KAOeeuO8",
    "outputId": "4e19f57b-10f9-4706-9c7d-52738516bf2d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYBnNbCyl3i6"
   },
   "source": [
    "## Standard Errors and Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7C08-QgfWerk"
   },
   "source": [
    "The **Standard Error** (SE) measures the variability of a sample statistic from the true population parameter. It reflects how much the sample statistic would vary if different samples were drawn from the same population.\n",
    "\n",
    "It is defined as the standard deviation of the sampling distribution of the statistic. From the CLT we know that the sample means follow a normal distribution with standard deviation $\\frac{\\sigma}{\\sqrt{n}}$, which is then the standard error for the sample mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqGg4kByThOw",
    "outputId": "e25b7d92-6b7d-417d-8d1f-2b5d93654216"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKwjFgB9YWtw"
   },
   "source": [
    "The standard error serves as a crucial component in calculating **confidence intervals**, which provide a range of plausible values for a population parameter, with a specified level of confidence. A confidence interval is computed from the data. Different random samples drawn from the same population produce different confidence intervals. The confidence level is the proportion of CIs that, as the number of samples increases, theoretically contain the true value of the parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8iTuRB2pWYZ"
   },
   "source": [
    "In general, the confidence interval for the estimate of a parameter $\\theta$ is given by:\n",
    "$$\n",
    "\\left[ \\widehat{\\theta} - c_{\\alpha} \\times \\text{SE}(\\widehat{\\theta}), \\quad \\widehat{\\theta} + c_{\\alpha} \\times \\text{SE}(\\widehat{\\theta}) \\right]\n",
    "$$\n",
    "where $c_{\\alpha}$ is the critical value of a relevant statistical distribution. The critical value is the point on the probability distribution that corresponds to the desired level of confidence. It represents the number of standard deviations away from the mean that captures the specified percentage of the data. The critical value is multiplied by the standard error of the sample statistic to calculate the margin of error, which defines how wide or narrow the confidence interval will be.\n",
    "\n",
    "The choice of the statistical distribution depends on the underlying sampling distribution of the statistic being estimated. We know that for large samples the distribution of sample means is approximately normal, even when the population distribution is not: that's why confidence intervals for the mean use z-values (critical values from a normal distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1o3uOLFUT1H5",
    "outputId": "8e5df86a-5114-420d-e933-daac0fc985ec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "PNFTggNanoJp",
    "outputId": "53f75f33-8bca-48e7-ae3a-3384b5c52f90"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjZ41ehiB9AM"
   },
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkXoPe50K4UH"
   },
   "source": [
    "The bootstrap is a resampling method used to estimate the distribution of a statistic by repeatedly drawing samples with replacement from the original data.\n",
    "\n",
    "Bootstrapping does not require assumptions about the distribution of the data, making it useful for non-normal data (or in general when the distribution is complex/unknown). It also provides better estimates than traditional theorethical methods when the sample size is small.\n",
    "\n",
    "It can be used for e.g. to construct confidence intervals and estimating the standard error of a statistic when traditional methods are not applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "Hf9WH-5tS0S4",
    "outputId": "efb042f8-ff04-4dec-c456-a3da0bf4abbb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2z2HZmTDQ7D"
   },
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQAgNUosijYc"
   },
   "source": [
    "A statistical hypothesis test is a method of statistical inference that tests whether the data sufficiently supports a particular hypothesis. In particular, it helps determine whether an observed effect is statistically significant or if it could have occurred by random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT45W5avjrW7"
   },
   "source": [
    "First, we define the null and alternative hypotheses. Typically, the alternative hypothesis $H_a$ simply posits that the null hypothesis $H_0$ does not hold. In order to find evidence for or against the null hypothesis, we must compute a test statistic T. The way in which we construct T depends on the nature of the null hypothesis that we are testing. The p-value is defined as the probability of observing a test statistic equal to or more extreme than the observed statistic, under the assumption that $H_0$ is true. Therefore, a small p-value provides evidence for rejecting $H_0$. Typical values to reject $H_0$ are 0.05 and 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p37c9i2BuC5g"
   },
   "source": [
    "A one-tailed test looks for statistical significance only on one tail of the distribution and thus we typically frame our null and alternative hypotheses using inequalities.\n",
    "\n",
    "In a two-tailed test, we frame null and alternative hypothesis in an “equal” and “not equal” structure. This means we spread our p-value statistical significance threshold to both tails, not just one. This means the two-tailed test makes it harder to reject the null hypothesis and demands stronger evidence to pass a test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhsjAvNm7dFM"
   },
   "source": [
    "There are numerous types of significance tests, depending on the type of data, how many samples there are, and what’s being measured. A very common one is the t-test, used for the comparison tests in which the data is numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "A7dcxZRTnUHq",
    "outputId": "3eb40c64-a34c-46c5-ea74-6989f33d08c3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "lPJYuQxspegt",
    "outputId": "8bcdaa9a-8b2b-4435-d5f8-989840b26a59"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pB4JOcA4r5bz"
   },
   "source": [
    "If we erroneously reject $H_0$ when it is true, we have a Type I error. If we do not reject $H_0$ when it is in false, we have a Type II error. The power of the hypothesis test is defined as the probability of not making a Type II error given that $H_a$ holds, i.e., the probability of correctly rejecting $H_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N2KnVnAGpJmS",
    "outputId": "5efed0c3-707b-44ea-edcb-c3c40353eaa3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsz1wxVa8WUK"
   },
   "source": [
    "The statistical procedure that tests for a statistically significant difference among multiple groups is called analysis of variance, or ANOVA. Just like the t-test can be used for comparing the mean of two groups, there is a statistical test for ANOVA based on the F-statistic. \n",
    "\n",
    "In a “one-way” ANOVA, we have one factor (group) that is varying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AVdmNF0nvsk",
    "outputId": "397a7d4e-54be-4560-f77c-1485f6a27afb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj2r5ZZx9QxN"
   },
   "source": [
    "The chi-square test is used with count data to test how well it fits some expected distribution. The most common use is with a contingency tables, to assess whether the null hypothesis of independence among variables is reasonable.\n",
    "\n",
    "Asymptotic statistical theory shows that the distribution of the chi-square statistic can be approximated by a chi-square distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGZO-Emcorx-",
    "outputId": "8be06ce5-635a-403d-a088-d3da174eb624"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQKkihhrGEd4"
   },
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv4FnX7vF7s8"
   },
   "source": [
    "## Linear vs Monotonic Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "rgb6Uje0F7s8",
    "outputId": "860c1600-9335-4812-bb37-43b043e080c6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uC4az7miF7s8"
   },
   "source": [
    "## Confounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "o3uDWSXqF7s8",
    "outputId": "490bb59b-5172-4046-d3a3-a4415240686b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtPYkbD-F7s8"
   },
   "source": [
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LFSzfAxF7s8",
    "outputId": "fec6ceb6-4052-43c5-93bb-ad488c897029"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Write a Python function that determines if the distribution of a pandas Series is symmetric, right-skewed or left-skewed.\n",
    "\n",
    "2) A disease affects 2% of a population. The population is divided into three age groups:\n",
    "\t•\tYoung (50%): False positive rate 3%, sensitivity 95%.\n",
    "\t•\tMiddle-aged (30%): False positive rate 4%, sensitivity 90%.\n",
    "\t•\tElderly (20%): False positive rate 5%, sensitivity 85%.\n",
    "\n",
    "N.B.\n",
    "False positive rate: probability of a person testing positive when they do not have the disease.\n",
    "Sensitivity/True positive rate: probability of a person testing positive when they have the disease.\n",
    "\n",
    "If a random person from the population tests positive, what is the probability they actually have the disease?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

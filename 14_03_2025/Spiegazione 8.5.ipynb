{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "960efdb6-7619-49bf-952e-2bb7cb2caaf5",
   "metadata": {},
   "source": [
    "# Concetti di base dell'intelligenza artificiale causale\n",
    "\n",
    "Questo quaderno introduce i concetti fondamentali dell'intelligenza artificiale causale con semplici esempi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2984f6cd-06eb-4400-b418-f486d3835422",
   "metadata": {},
   "source": [
    "## 1. Correlazione vs. Causalità\n",
    "\n",
    "Il concetto di **correlazione** e **causalità** è fondamentale in vari ambiti, inclusa l'intelligenza artificiale (IA). Vediamoli separatamente e poi nel contesto dell'IA:\n",
    "\n",
    "### 1. **Correlazione**\n",
    "La **correlazione** indica una relazione statistica tra due o più variabili, ma non implica che una variabile causi l'altra. In altre parole, quando due variabili sono correlate, significa che tendono a muoversi insieme in qualche modo, ma non possiamo affermare con certezza che una sia la causa dell'altra. La correlazione può essere positiva (quando entrambe le variabili crescono o decrescono insieme) o negativa (quando una cresce mentre l'altra diminuisce).\n",
    "\n",
    "Ad esempio, se osserviamo che in una determinata città aumentano le vendite di gelati durante l'estate e anche il numero di incidenti stradali, potremmo notare una **correlazione positiva** tra le due variabili. Tuttavia, ciò non significa che mangiare più gelati causi gli incidenti stradali. Probabilmente c'è una terza variabile, come l'aumento del traffico durante l'estate, che sta influenzando entrambe le cose.\n",
    "\n",
    "### 2. **Causalità**\n",
    "La **causalità**, invece, implica una relazione di causa ed effetto tra due variabili. Se esiste una causalità, significa che una variabile ha un impatto diretto sull'altra. La causalità suggerisce che un cambiamento in una variabile **causa** un cambiamento nell'altra.\n",
    "\n",
    "Nel contesto dell'IA, la causalità è molto importante per fare inferenze corrette e per prendere decisioni basate sui dati. Se l'IA rileva una correlazione, ma non considera la causalità, potrebbe trarre conclusioni errate. Ad esempio, se un algoritmo di IA osserva che quando piove le vendite di ombrelli aumentano, potrebbe **correlare** la pioggia con le vendite degli ombrelli. Tuttavia, la causalità suggerirebbe che la pioggia causa un aumento delle vendite di ombrelli.\n",
    "\n",
    "### Correlazione vs Causalità nell'Intelligenza Artificiale\n",
    "Nell'IA, la **correlazione** è spesso utilizzata per fare predizioni, ma è importante che gli algoritmi non confondano una correlazione con una vera relazione causale. Un algoritmo potrebbe, ad esempio, imparare che esiste una forte correlazione tra due variabili, ma senza capire il meccanismo sottostante che le collega.\n",
    "\n",
    "Ad esempio:\n",
    "- **Correlazione:** Un algoritmo può rilevare che c'è una correlazione tra il numero di ore di studio e i voti ottenuti in un esame, ma ciò non significa necessariamente che l'aumento delle ore di studio causi direttamente un miglioramento nei voti (potrebbero esserci altri fattori, come la qualità dello studio o la motivazione).\n",
    "- **Causalità:** Un altro modello IA potrebbe essere progettato per cercare di determinare se c'è una vera causalità, utilizzando metodi come esperimenti controllati, analisi di regressione causale o approcci basati su grafi causali.\n",
    "\n",
    "In sintesi:\n",
    "- **Correlazione** mostra semplicemente che due eventi tendono a verificarsi insieme, ma non ci dice nulla su quale dei due eventi influenzi l'altro.\n",
    "- **Causalità** implica che un evento **provoca** un altro evento, e questa relazione è fondamentale per fare previsioni affidabili e per prendere decisioni informate, specialmente nell'IA.\n",
    "\n",
    "Capire e distinguere tra questi due concetti è cruciale quando si progettano modelli di IA che devono operare in modo preciso e coerente con il mondo reale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c0cd03-e675-4881-9ccb-e0bdfa3b2ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between ice cream sales and drownings: 0.69\n",
      "Despite high correlation, ice cream doesn't cause drownings - temperature affects both!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate synthetic data where ice cream sales and drowning incidents are both caused by temperature\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "temperature = np.random.normal(25, 5, n)  # Mean 25°C, std 5°C\n",
    "ice_cream_sales = 100 + 20 * temperature + np.random.normal(0, 50, n)  # Affected by temperature\n",
    "drownings = 5 + 0.8 * temperature + np.random.normal(0, 3, n)  # Also affected by temperature\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Temperature': temperature,\n",
    "    'Ice_Cream_Sales': ice_cream_sales,\n",
    "    'Drownings': drownings\n",
    "})\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = data['Ice_Cream_Sales'].corr(data['Drownings'])\n",
    "print(f\"Correlation between ice cream sales and drownings: {correlation:.2f}\")\n",
    "print(\"Despite high correlation, ice cream doesn't cause drownings - temperature affects both!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c107c3-bb4a-4494-8fa4-d5207c73ad92",
   "metadata": {},
   "source": [
    " Questo esempio illustra molto bene il concetto di **correlazione** e **causalità**.\n",
    "\n",
    "### **Cosa fa il codice?**\n",
    "\n",
    "Nel codice che hai fornito, viene generato un dataset sintetico con tre variabili:\n",
    "1. **Temperatura**: la temperatura media in gradi Celsius.\n",
    "2. **Vendite di gelati**: vendite di gelati che dipendono dalla temperatura.\n",
    "3. **Incidenti di annegamento**: il numero di incidenti di annegamento che dipendono anch'essi dalla temperatura.\n",
    "\n",
    "### **Correlazione**\n",
    "Alla fine del codice, viene calcolata la **correlazione** tra le vendite di gelati e gli incidenti di annegamento. La correlazione è un numero che indica la forza e la direzione della relazione lineare tra due variabili. Può variare da -1 (relazione inversa perfetta) a +1 (relazione diretta perfetta), con 0 che indica nessuna correlazione.\n",
    "\n",
    "Nel tuo esempio, anche se la **correlazione** tra **gelati venduti** e **incidenti di annegamento** potrebbe risultare alta, questo non implica che le vendite di gelati causino gli incidenti di annegamento.\n",
    "\n",
    "### **Il concetto di Causalità**\n",
    "La chiave qui è che **temperatura** è la causa sottostante che influisce su entrambe le variabili:\n",
    "- **Temperatura e gelati**: quando fa più caldo, le persone comprano più gelati.\n",
    "- **Temperatura e annegamenti**: quando fa caldo, più persone vanno in acqua, e quindi c'è un aumento degli incidenti di annegamento.\n",
    "\n",
    "Nonostante l'alta **correlazione** tra vendite di gelati e annegamenti, la **causalità** non esiste tra questi due fenomeni. Non è che vendere più gelati faccia aumentare gli incidenti di annegamento, ma entrambi sono influenzati dalla stessa causa: la **temperatura**.\n",
    "\n",
    "### **Perché è importante?**\n",
    "In questo esempio, il calcolo della correlazione potrebbe portare a una conclusione errata se non si considera il contesto causale. Se qualcuno osservasse solo la correlazione tra gelati e annegamenti senza comprendere il fattore comune (la temperatura), potrebbe erroneamente pensare che vendere più gelati **causi** più annegamenti. In realtà, la **temperatura** è il fattore causale che porta sia ad un aumento delle vendite di gelati che ad un aumento degli annegamenti.\n",
    "\n",
    "### **Riepilogo:**\n",
    "- **Correlazione**: Le due variabili (gelati venduti e annegamenti) sono correlate perché entrambe sono influenzate dalla temperatura.\n",
    "- **Causalità**: Non esiste causalità diretta tra gelati e annegamenti, ma entrambe le variabili sono causate dalla temperatura.\n",
    "\n",
    "Questo esempio è un ottimo modo per ricordare che **correlazione non implica causalità**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b997d3-6ab2-4650-81a8-e61d1f4aed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a simple causal graph\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([\n",
    "    ('Temperature', 'Ice_Cream_Sales'),\n",
    "    ('Temperature', 'Drownings'),\n",
    "])\n",
    "\n",
    "# Uncomment to display graph (requires graphviz)\n",
    "# import matplotlib.pyplot as plt\n",
    "# pos = nx.spring_layout(G)\n",
    "# nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=2000, arrowsize=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7d6c8-6f6b-4b6b-8af9-c6832ae9824e",
   "metadata": {},
   "source": [
    "Un **grafico causale**, o **grafico aciclico diretto (DAG)**, è uno strumento utilizzato per rappresentare visivamente le relazioni causali tra variabili. Il DAG è un tipo di **grafo orientato** che mostra come una variabile influenzi un’altra, senza cicli (da qui \"aciclico\"). È uno strumento molto utile in statistica, machine learning e intelligenza artificiale per modellare e comprendere le dinamiche causali.\n",
    "\n",
    "### Cos'è un DAG?\n",
    "\n",
    "- **Grafico**: un grafo è una struttura composta da nodi (o vertici) e archi (o collegamenti).\n",
    "- **Aciclico**: significa che non ci sono cicli, ossia non c'è nessuna sequenza di archi che porta da un nodo a se stesso.\n",
    "- **Diretto**: significa che ogni arco ha una direzione, da una variabile a un'altra, e indica la direzione della relazione causale.\n",
    "\n",
    "### **Elementi di un DAG**\n",
    "1. **Nodi**: rappresentano le variabili (ad esempio, \"Temperatura\", \"Gelati venduti\", \"Annegamenti\").\n",
    "2. **Archi diretti**: le frecce che vanno da un nodo all'altro, rappresentano la direzione causale. Per esempio, una freccia da \"Temperatura\" a \"Gelati venduti\" implica che la temperatura influenza le vendite di gelati.\n",
    "\n",
    "### **Esempio di DAG**\n",
    "\n",
    "Immagina di avere tre variabili: **Temperatura**, **Gelati venduti** e **Annegamenti**. In un DAG, potresti rappresentarle come segue:\n",
    "\n",
    "- La **Temperatura** influenza sia le **Vendite di Gelati** (perché le vendite aumentano con l'aumento della temperatura) sia gli **Incidenti di Annegamento** (perché più persone vanno al mare quando fa caldo).\n",
    "- **Vendite di Gelati** e **Annegamenti** non hanno una relazione causale diretta tra di loro, ma sono entrambe influenzate dalla **Temperatura**.\n",
    "\n",
    "Il DAG sarebbe quindi rappresentato come:\n",
    "\n",
    "```\n",
    "      Temperatura\n",
    "        /      \\\n",
    " Gelati venduti  Annegamenti\n",
    "```\n",
    "\n",
    "In questo caso:\n",
    "- **Temperatura → Gelati venduti**: la temperatura influisce sulle vendite di gelati.\n",
    "- **Temperatura → Annegamenti**: la temperatura influisce sugli incidenti di annegamento.\n",
    "- Non c'è una freccia tra **Gelati venduti** e **Annegamenti**, perché non c'è relazione causale diretta tra di loro, ma solo attraverso la temperatura.\n",
    "\n",
    "### **Caratteristiche principali di un DAG**\n",
    "1. **Aciclicità**: Non ci sono cicli. Non puoi tornare a un nodo partendo da un altro nodo seguendo gli archi, il che significa che ogni variabile ha una direzione causale chiara.\n",
    "   \n",
    "2. **Direzionalità**: Le frecce indicano quale variabile causa un cambiamento nell'altra. Ad esempio, \"Temperatura → Gelati venduti\" implica che un cambiamento nella temperatura causa un cambiamento nelle vendite di gelati.\n",
    "\n",
    "3. **Causalità**: Il DAG aiuta a capire come le variabili sono connesse causalmente. Ad esempio, se vogliamo capire come cambia il rischio di annegamento in relazione alle temperature, possiamo vedere nel DAG che la **Temperatura** è la causa principale di entrambi i fenomeni.\n",
    "\n",
    "### **Utilizzo dei DAG**\n",
    "I DAG sono usati in molte aree per:\n",
    "- **Comprendere relazioni causali**: Identificare quale variabile influenza un'altra e come le variabili si collegano.\n",
    "- **Causalità nelle scienze sociali e biomediche**: Modellare sistemi complessi, come in epidemiologia, economia e scienze sociali, per fare inferenze causali.\n",
    "- **Machine Learning**: In alcune tecniche di apprendimento causale, i DAG aiutano a determinare quali variabili dovrebbero essere incluse nel modello e come le variabili influenzano i risultati.\n",
    "- **Inferenza causale**: In statistica, i DAG sono usati per eseguire analisi di inferenza causale, dove si cerca di determinare l'effetto causale di una variabile su un'altra.\n",
    "\n",
    "### **Conclusioni**\n",
    "- Un **DAG** è uno strumento visivo potente per modellare le relazioni causali tra variabili.\n",
    "- Aiuta a distinguere tra **correlazione** e **causalità**. Una correlazione tra due variabili non implica che una causi l'altra, ma un DAG può mostrare come una variabile influenzi l'altra.\n",
    "- È ampiamente utilizzato in statistica, epidemiologia, machine learning e in molti altri campi per inferenze causali e analisi di modelli complessi.\n",
    "\n",
    "Spero che questa spiegazione ti abbia chiarito il concetto di grafici causali e DAG! Se hai domande aggiuntive, chiedi pure!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce8970a-3c10-4ee5-b802-ff92142668da",
   "metadata": {},
   "source": [
    "## 3. Interventi (do-calculus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30cad6c9-f275-49e3-a009-68c0662df097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average drownings when observing high ice cream sales: 28.58\n",
      "Average drownings when intervening on ice cream sales: 24.78\n",
      "The intervention shows that ice cream sales don't affect drownings!\n"
     ]
    }
   ],
   "source": [
    "# Simulazione di un intervento (do-operator)\n",
    "def observe_ice_cream(sales_level):\n",
    "    \"\"\"Filter data based on observed ice cream sales\"\"\"\n",
    "    return data[data['Ice_Cream_Sales'] > sales_level]\n",
    "\n",
    "def do_ice_cream(sales_level):\n",
    "    \"\"\"Simulate intervention where we set ice cream sales to a specific level\"\"\"\n",
    "    # In a do-intervention, we break the link from Temperature to Ice_Cream_Sales\n",
    "    # This means drownings will still be determined by temperature, not by ice cream sales\n",
    "    \n",
    "    # Crea un nuovo dataframe con gli stessi valori di temperatura e annegamento\n",
    "    intervened_data = data.copy()\n",
    "    # Set all ice cream sales to the intervention level\n",
    "    intervened_data['Ice_Cream_Sales'] = sales_level\n",
    "    return intervened_data\n",
    "\n",
    "# Confronta osservazione vs. intervento\n",
    "high_observed = observe_ice_cream(600)\n",
    "high_intervened = do_ice_cream(600)\n",
    "\n",
    "print(f\"Average drownings when observing high ice cream sales: {high_observed['Drownings'].mean():.2f}\")\n",
    "print(f\"Average drownings when intervening on ice cream sales: {high_intervened['Drownings'].mean():.2f}\")\n",
    "print(\"The intervention shows that ice cream sales don't affect drownings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820ce18-e767-4b10-8670-0b76b246cfa7",
   "metadata": {},
   "source": [
    " Questo codice simula un tipo di intervento in un esperimento che riguarda le vendite di gelato e le annegamenti. In particolare, il codice confronta la situazione \"osservata\" (dove le vendite di gelato dipendono dalle variabili esterne come la temperatura) con la situazione \"intervenuta\" (dove le vendite di gelato sono impostate a un livello fisso, indipendentemente da altre variabili).\n",
    "\n",
    "### Funzioni:\n",
    "\n",
    "1. **`observe_ice_cream(sales_level)`**:\n",
    "   - Questa funzione filtra i dati per selezionare solo quelli in cui le vendite di gelato sono superiori a un certo livello (`sales_level`). Di fatto, è come se osservassimo la situazione \"naturale\" dove le vendite di gelato seguono una relazione con altre variabili (ad esempio, la temperatura).\n",
    "\n",
    "2. **`do_ice_cream(sales_level)`**:\n",
    "   - Questa funzione simula un intervento, in cui \"forziamo\" le vendite di gelato a un certo livello (`sales_level`), senza tener conto delle influenze naturali (ad esempio, la temperatura). In pratica, questo simula un esperimento in cui diciamo \"cosa succederebbe se le vendite di gelato fossero sempre uguali, indipendentemente dalle condizioni meteorologiche?\".\n",
    "   - In questo caso, la funzione copia i dati originali e poi imposta tutte le vendite di gelato al valore di `sales_level` specificato. Questo crea una nuova versione dei dati, dove le vendite di gelato non sono più legate alla temperatura.\n",
    "\n",
    "### Cosa viene confrontato?\n",
    "\n",
    "Il codice confronta due scenari:\n",
    "\n",
    "1. **Osservazione (high_observed)**: Qui guardiamo cosa succede quando le vendite di gelato sono elevate (superiori a 600). In altre parole, osserviamo la situazione naturale, dove le vendite di gelato potrebbero essere influenzate dalla temperatura e, a sua volta, potrebbero influenzare i tassi di annegamento.\n",
    "\n",
    "2. **Intervento (high_intervened)**: Qui impostiamo il livello delle vendite di gelato a 600 (indipendentemente da altre variabili) e vediamo come cambia la situazione. La relazione tra temperatura e vendite di gelato è \"interrotta\", quindi i tassi di annegamento vengono determinati solo dalla temperatura, non dalle vendite di gelato.\n",
    "\n",
    "### Cosa significa il risultato?\n",
    "\n",
    "- **Nel caso osservato** (alta vendita di gelato), possiamo vedere che i tassi di annegamento sono influenzati da un livello di vendite di gelato elevato, ma ciò potrebbe essere dovuto a fattori come la temperatura, che influenzano sia le vendite di gelato che gli annegamenti.\n",
    "  \n",
    "- **Nel caso dell'intervento** (con vendite di gelato fissate a un livello specifico), i tassi di annegamento non sono più influenzati dalle vendite di gelato, ma solo dalla temperatura, come ci si aspetterebbe in un esperimento controllato.\n",
    "\n",
    "### Conclusione:\n",
    "\n",
    "La stampa finale \"The intervention shows that ice cream sales don't affect drownings!\" suggerisce che, una volta rimosso l'effetto delle vendite di gelato (forzandole a un valore costante), possiamo vedere che le vendite di gelato **non influenzano direttamente** i tassi di annegamento. In altre parole, la correlazione che vediamo osservando i dati potrebbe essere dovuta a una variabile nascosta (come la temperatura), piuttosto che una vera e propria relazione causale tra gelato e annegamenti.\n",
    "\n",
    "In sintesi, l'intervento aiuta a separare la causa effettiva (la temperatura) dall'effetto osservato (le vendite di gelato), mostrando che le vendite di gelato non causano direttamente gli annegamenti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adfe4ea-2e46-471b-9e44-e32f11dd8e35",
   "metadata": {},
   "source": [
    "## 4. Controfattuali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a640d87-22dd-40e5-8f50-10dcae71060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original scenario: 34.3°C with 33.1 drownings\n",
      "Counterfactual: If temperature was 24.3°C, drownings would be 25.1\n",
      "Lives potentially saved: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Esempio controfattuale: cosa sarebbe successo se avessimo controllato la temperatura??\n",
    "def counterfactual_temperature_control(row, target_temp):\n",
    "    \"\"\"Generate counterfactual: What if temperature had been 'target_temp' instead?\"\"\"\n",
    "    # Calculate how ice cream sales and drownings would change\n",
    "    temp_diff = target_temp - row['Temperature']\n",
    "    \n",
    "    # Calcola i valori controfattuali\n",
    "    cf_ice_cream = row['Ice_Cream_Sales'] + 20 * temp_diff  # Utilizzando il nostro noto modello causale\n",
    "    cf_drownings = row['Drownings'] + 0.8 * temp_diff       # Utilizzando il nostro noto modello causale\n",
    "    \n",
    "    return pd.Series({\n",
    "        'Original_Temp': row['Temperature'],\n",
    "        'Counterfactual_Temp': target_temp,\n",
    "        'Original_Drownings': row['Drownings'],\n",
    "        'Counterfactual_Drownings': cf_drownings\n",
    "    })\n",
    "\n",
    "# Scegli un giorno specifico e chiediti: cosa sarebbe successo se la temperatura fosse stata più bassa?\n",
    "hot_day = data.iloc[data['Temperature'].argmax()]\n",
    "counterfactual = counterfactual_temperature_control(hot_day, hot_day['Temperature'] - 10)\n",
    "\n",
    "print(f\"Original scenario: {counterfactual['Original_Temp']:.1f}°C with {counterfactual['Original_Drownings']:.1f} drownings\")\n",
    "print(f\"Counterfactual: If temperature was {counterfactual['Counterfactual_Temp']:.1f}°C, drownings would be {counterfactual['Counterfactual_Drownings']:.1f}\")\n",
    "print(f\"Lives potentially saved: {counterfactual['Original_Drownings'] - counterfactual['Counterfactual_Drownings']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad93b4-a9c5-4c1d-8e57-04b859bdf26e",
   "metadata": {},
   "source": [
    "Questo codice sta cercando di calcolare un **controfattuale**, ovvero una simulazione di come sarebbero andate le cose se un determinato fattore (in questo caso la **temperatura**) fosse stato diverso in passato.\n",
    "\n",
    "### Funzioni:\n",
    "\n",
    "1. **`counterfactual_temperature_control(row, target_temp)`**:\n",
    "   - Questa funzione genera un *controfattuale* (una simulazione di ciò che sarebbe potuto accadere) cambiando la temperatura in un giorno specifico (`target_temp`), ma mantenendo il resto invariato.\n",
    "   - La funzione prende come input una riga di dati (`row`) che contiene informazioni su un giorno specifico (ad esempio, la temperatura e i tassi di annegamento) e un `target_temp` (la temperatura che vogliamo simulare).\n",
    "   - Poi calcola le **variazioni** in due variabili: \n",
    "     - **Vendite di gelato**: Supponendo che la variazione di temperatura influisca sulle vendite di gelato in base a una relazione causale che dice che per ogni grado di differenza nella temperatura, le vendite di gelato cambiano di 20 unità.\n",
    "     - **Annegamenti**: La variazione nella temperatura influisce anche sul numero di annegamenti. Si assume che per ogni grado di differenza, il numero di annegamenti cambi di 0,8.\n",
    "   - La funzione restituisce una serie di valori, che include la temperatura originale, quella controfattuale, il numero di annegamenti originali e quello controfattuale.\n",
    "\n",
    "### Cosa fa il codice?\n",
    "\n",
    "1. **Seleziona un giorno caldo**: \n",
    "   - `hot_day = data.iloc[data['Temperature'].argmax()]`\n",
    "     - Qui si seleziona il giorno con la **temperatura massima** (il giorno più caldo nel dataset) utilizzando la funzione `argmax()` per trovare l'indice della temperatura massima. Poi si estrae la riga corrispondente a quel giorno dal dataframe `data`.\n",
    "\n",
    "2. **Calcola il controfattuale**:\n",
    "   - `counterfactual = counterfactual_temperature_control(hot_day, hot_day['Temperature'] - 10)`\n",
    "     - Qui si simula come sarebbero andate le cose se la temperatura in quel giorno fosse stata **10 gradi inferiore**. Passiamo la riga con i dati del giorno più caldo (`hot_day`) e impostiamo la temperatura target come `hot_day['Temperature'] - 10`.\n",
    "\n",
    "3. **Stampa i risultati**:\n",
    "   - Il codice poi stampa la temperatura originale e quella controfattuale, insieme al numero di annegamenti originale e quello simulato, e infine calcola il numero di **vite potenzialmente salvate** (ossia la differenza tra i tassi di annegamento originali e quelli controfattuali).\n",
    "   \n",
    "### Interpretazione dei risultati:\n",
    "\n",
    "Ad esempio, se il giorno più caldo aveva una temperatura di 35°C e 5 annegamenti, e nel controfattuale simuli che la temperatura fosse stata 25°C (10 gradi in meno), il codice ti dirà come cambierebbero i tassi di annegamento (secondo il modello causale ipotizzato).\n",
    "\n",
    "- **Scenario originale**: Ti dirà quanti annegamenti ci sono stati a quella temperatura (ad esempio, 5 annegamenti con 35°C).\n",
    "- **Controfattuale**: Ti dirà quanti annegamenti ci sarebbero stati se la temperatura fosse stata 25°C (secondo la relazione causale, ad esempio 3,5 annegamenti con 25°C).\n",
    "- **Vite salvate**: La differenza tra gli annegamenti originali e quelli controfattuali rappresenta il numero di **vite salvate** se la temperatura fosse stata più bassa (ad esempio, 5 - 3,5 = 1,5 vite salvate).\n",
    "\n",
    "### Perché è utile?\n",
    "\n",
    "Questo tipo di analisi è utile per comprendere l'effetto di una variabile (in questo caso la temperatura) su un'altra (gli annegamenti). Il controfattuale ci permette di fare previsioni su **cosa sarebbe successo in un mondo alternativo** (ad esempio, se la temperatura fosse stata diversa). Questo può aiutare a capire se una politica di controllo della temperatura (ad esempio, l'adozione di misure per ridurre il caldo) potrebbe effettivamente ridurre i tassi di annegamento.\n",
    "\n",
    "### Riassunto:\n",
    "\n",
    "- Il codice confronta il numero di annegamenti osservati in un giorno caldo con quelli che si sarebbero verificati in un controfattuale in cui la temperatura fosse stata più bassa.\n",
    "- Usa un modello causale per stimare come la temperatura influisce su vendite di gelato e annegamenti, e calcola quante vite potrebbero essere state salvate se la temperatura fosse stata diversa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6364832-a58a-4647-b575-917c601483c4",
   "metadata": {},
   "source": [
    "## 5. Corrispondenza del punteggio di propensione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef68b394-ed51-4a64-850c-295642684a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive estimate of treatment effect: 0.17\n",
      "This is biased because sicker patients tend to get treatment\n",
      "Estimated treatment effect using propensity matching: 3.97\n",
      "With better matching and larger samples, this would approach the true effect of 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_9848\\1141727883.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_9848\\1141727883.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_9848\\1141727883.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_9848\\1141727883.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_9848\\1141727883.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n"
     ]
    }
   ],
   "source": [
    "# Generare dati sull'effetto del trattamento\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# Covariate\n",
    "age = np.random.normal(40, 10, n)\n",
    "severity = np.random.normal(5, 2, n)\n",
    "\n",
    "# Assegnazione del trattamento (influenzata dalle covariate)\n",
    "# I pazienti più anziani e i casi più gravi hanno maggiori probabilità di ricevere cure\n",
    "propensity = 1 / (1 + np.exp(-(age - 40) / 10 - severity + 2))\n",
    "treatment = np.random.binomial(1, propensity)\n",
    "\n",
    "# Risultato (il vero effetto del trattamento è +5)\n",
    "# La gravità influisce negativamente sul risultato, l'età ha un piccolo effetto\n",
    "outcome = 70 - 2 * severity + 0.1 * age + 5 * treatment + np.random.normal(0, 3, n)\n",
    "\n",
    "treatment_data = pd.DataFrame({\n",
    "    'Age': age,\n",
    "    'Severity': severity,\n",
    "    'Treatment': treatment,\n",
    "    'Outcome': outcome,\n",
    "    'Propensity': propensity\n",
    "})\n",
    "\n",
    "# Naive estimate (distorta a causa di fattori confondenti)\n",
    "treated = treatment_data[treatment_data['Treatment'] == 1]['Outcome'].mean()\n",
    "untreated = treatment_data[treatment_data['Treatment'] == 0]['Outcome'].mean()\n",
    "print(f\"Naive estimate of treatment effect: {treated - untreated:.2f}\")\n",
    "print(\"This is biased because sicker patients tend to get treatment\")\n",
    "\n",
    "# Corrispondenza semplice del punteggio di propensione\n",
    "def match_patient(patient, treatment_group, n_matches=1):\n",
    "    \"\"\"Find matching patients from the opposite treatment group\"\"\"\n",
    "    opposite_group = treatment_data[treatment_data['Treatment'] != treatment_group]\n",
    "    \n",
    "    # Calcola la distanza del punteggio di propensione\n",
    "    opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n",
    "    \n",
    "    # Restituisce n corrispondenze più vicine\n",
    "    return opposite_group.nsmallest(n_matches, 'distance')\n",
    "\n",
    "# Prendi un campione di alcuni pazienti trattati e trova le loro corrispondenze\n",
    "sample_treated = treatment_data[treatment_data['Treatment'] == 1].sample(5)\n",
    "matched_outcomes = []\n",
    "\n",
    "for _, patient in sample_treated.iterrows():\n",
    "    matches = match_patient(patient, 1, n_matches=1)\n",
    "    effect = patient['Outcome'] - matches['Outcome'].values[0]\n",
    "    matched_outcomes.append(effect)\n",
    "\n",
    "print(f\"Estimated treatment effect using propensity matching: {np.mean(matched_outcomes):.2f}\")\n",
    "print(\"With better matching and larger samples, this would approach the true effect of 5.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98613639-fe3a-46cf-8f64-19a3973d6575",
   "metadata": {},
   "source": [
    "Questo codice crea un **simulazione di trattamento** in un contesto medico (o simile), per stimare l'effetto di un trattamento su un risultato (come una misura di salute) utilizzando tecniche di **matching** basate sul **propensity score** (PSM - Propensity Score Matching). Vediamo passo passo cosa succede:\n",
    "\n",
    "### **1. Generazione dei dati simulati**\n",
    "   - **`np.random.seed(42)`**: Imposta il seme del generatore di numeri casuali per garantire che i risultati siano riproducibili.\n",
    "   - **Variabili di base (covariate)**:\n",
    "     - `age`: L'età dei pazienti, generata come variabile casuale normale con media 40 e deviazione standard di 10.\n",
    "     - `severity`: La gravità del caso, anche questa generata come variabile normale con media 5 e deviazione standard di 2.\n",
    "\n",
    "### **2. Assegnazione del trattamento**\n",
    "   - **`propensity`**: Calcola la probabilità che un paziente riceva il trattamento, data la sua età (`age`) e la gravità del caso (`severity`). La probabilità viene calcolata tramite una funzione logistica, che fa sì che pazienti più anziani e con casi più gravi abbiano una probabilità maggiore di ricevere il trattamento.\n",
    "   - **`treatment`**: L'assegnazione effettiva del trattamento viene simulata come una variabile binaria (0 o 1), con probabilità definita dal **propensity score** calcolato sopra.\n",
    "\n",
    "### **3. Generazione dell'outcome**\n",
    "   - **`outcome`**: Calcola il risultato di salute (ad esempio, un punteggio di salute), che dipende da:\n",
    "     - La gravità del caso (maggiore gravità riduce l'outcome, quindi l'effetto di `severity` è negativo).\n",
    "     - L'età (ha un piccolo effetto positivo sull'outcome).\n",
    "     - Il trattamento ricevuto (i pazienti trattati guadagnano un effetto positivo di 5, simile a un \"effetto causale\" del trattamento).\n",
    "   - Inoltre, c'è un termine di errore casuale per rendere i dati più realistici.\n",
    "\n",
    "### **4. Creazione del dataframe**\n",
    "   - Il codice crea un dataframe chiamato `treatment_data` che contiene tutte le variabili generate: `Age`, `Severity`, `Treatment`, `Outcome` e `Propensity`.\n",
    "\n",
    "### **5. Stima naive dell'effetto del trattamento (con confondimento)**\n",
    "   - **`treated`**: Calcola la media dell'outcome per i pazienti trattati (`Treatment == 1`).\n",
    "   - **`untreated`**: Calcola la media dell'outcome per i pazienti non trattati (`Treatment == 0`).\n",
    "   - La differenza tra queste due medie viene presa come la stima dell'effetto del trattamento. Tuttavia, questa stima è **distorta** (o \"biased\") perché i pazienti con casi più gravi (che potrebbero naturalmente avere esiti peggiori) tendono a ricevere il trattamento più frequentemente. Questo è un esempio di **confondimento**, in cui la relazione tra trattamento e outcome è influenzata da una variabile esterna (in questo caso, la gravità del caso).\n",
    "\n",
    "### **6. Stima dell'effetto del trattamento usando il **Propensity Score Matching** (PSM)**\n",
    "   - **`match_patient`**: Questa funzione cerca pazienti trattati e non trattati con punteggi di propensità simili. In pratica, questa funzione esegue il **matching** per abbinare pazienti trattati a quelli non trattati con caratteristiche simili.\n",
    "     - Si calcola la \"distanza\" tra il punteggio di propensità di un paziente trattato e quelli non trattati.\n",
    "     - I pazienti che hanno la distanza di propensità più piccola vengono selezionati come \"match\".\n",
    "   - **Matching dei pazienti trattati**:\n",
    "     - Vengono selezionati alcuni pazienti trattati casualmente (5 in questo caso) e per ognuno di questi viene trovato un paziente non trattato con un punteggio di propensità simile.\n",
    "   - **Calcolo dell'effetto del trattamento**:\n",
    "     - Per ogni paziente trattato, si calcola l'effetto del trattamento come la differenza tra l'outcome del paziente trattato e quello del paziente abbinato non trattato.\n",
    "\n",
    "### **7. Risultato finale**\n",
    "   - Il codice calcola la **media dell'effetto del trattamento stimato** utilizzando il matching dei punteggi di propensità.\n",
    "   - La stampa finale mostra l'**effetto del trattamento stimato** dopo il matching, che sarà meno distorto rispetto alla stima \"naive\" iniziale.\n",
    "\n",
    "### **Obiettivo e conclusione**\n",
    "   - L'obiettivo di questo codice è confrontare una stima **naive** (non corretta per il confondimento) dell'effetto del trattamento con una stima **corretta** utilizzando la tecnica del **propensity score matching**. La stima finale ottenuta dal matching dovrebbe essere più accurata, avvicinandosi al \"vero\" effetto del trattamento, che nel modello simulato è 5.\n",
    "   - Il commento finale indica che **con un campione maggiore e un matching migliore**, la stima dell'effetto del trattamento si avvicinerà al vero valore di 5, che è l'effetto causale reale in questo modello simulato.\n",
    "\n",
    "### **Riassunto finale**:\n",
    "Il codice simula un esperimento in cui un trattamento (ad esempio, un farmaco o un intervento) viene somministrato a pazienti in base a determinate caratteristiche, come età e gravità del caso. Utilizzando il **propensity score matching**, il codice stima l'effetto del trattamento cercando di correggere il bias dovuto al fatto che i pazienti con caratteristiche diverse (come gravità del caso) potrebbero ricevere il trattamento in modo non casuale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fe3714-89ba-4430-a3d7-cec159849b61",
   "metadata": {},
   "source": [
    "## 6. Variabili strumentali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79744e66-77eb-454e-af74-1b519d8975c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive regression (biased due to omitted ability variable):\n",
      "Estimated return to education: $3242.61 per year\n",
      "\n",
      "Instrumental variables estimate (using distance to college):\n",
      "Estimated return to education: $2689.58 per year\n",
      "This is closer to the true causal effect of $3000 per year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_9848\\2237348427.py:32: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f\"Estimated return to education: ${model.params[1]:.2f} per year\")\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_9848\\2237348427.py:45: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f\"Estimated return to education: ${second_stage.params[1]:.2f} per year\")\n"
     ]
    }
   ],
   "source": [
    "# Esempio: Effetto dell'istruzione sui guadagni utilizzando la distanza dall'università come strumento\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "# Fattore confondente non osservato: capacità\n",
    "ability = np.random.normal(100, 15, n)\n",
    "\n",
    "# Strumento: distanza dal college più vicino (km)\n",
    "# Not affected by ability or other confounders\n",
    "distance_to_college = np.random.gamma(2, 20, n)\n",
    "\n",
    "# Anni di istruzione (influenzati dalla distanza e dalla capacità)\n",
    "education = 12 + 5 - 0.05 * distance_to_college + 0.04 * ability + np.random.normal(0, 1, n)\n",
    "education = np.maximum(education, 8)  # Minimum 8 years of education\n",
    "\n",
    "# Guadagni (influenzati da istruzione e capacità)\n",
    "earnings = 20000 + 3000 * (education - 12) + 200 * ability + np.random.normal(0, 5000, n)\n",
    "\n",
    "iv_data = pd.DataFrame({\n",
    "    'Distance_to_College': distance_to_college,\n",
    "    'Education_Years': education,\n",
    "    'Earnings': earnings,\n",
    "    'Ability': ability  # Would be unobserved in real data\n",
    "})\n",
    "\n",
    "# Naive regression (distorto a causa di fattori confondenti non osservati)\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(iv_data['Education_Years'])\n",
    "model = sm.OLS(iv_data['Earnings'], X).fit()\n",
    "print(\"Naive regression (biased due to omitted ability variable):\")\n",
    "print(f\"Estimated return to education: ${model.params[1]:.2f} per year\")\n",
    "\n",
    "# Minimi quadrati a due stadi (2SLS) per variabili strumentali\n",
    "# Prima fase: regressione dell'istruzione sullo strumento\n",
    "X_first = sm.add_constant(iv_data['Distance_to_College'])\n",
    "first_stage = sm.OLS(iv_data['Education_Years'], X_first).fit()\n",
    "iv_data['Predicted_Education'] = first_stage.predict(X_first)\n",
    "\n",
    "# Seconda fase: regressione dei guadagni in base all'istruzione prevista\n",
    "X_second = sm.add_constant(iv_data['Predicted_Education'])\n",
    "second_stage = sm.OLS(iv_data['Earnings'], X_second).fit()\n",
    "\n",
    "print(\"\\nInstrumental variables estimate (using distance to college):\")\n",
    "print(f\"Estimated return to education: ${second_stage.params[1]:.2f} per year\")\n",
    "print(\"This is closer to the true causal effect of $3000 per year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f3bcb1-d0fb-4f95-855c-31df2bdeb815",
   "metadata": {},
   "source": [
    "Questo codice utilizza il concetto di **variabili strumentali** (instrumental variables, IV) per stimare l'effetto causale dell'**istruzione** sul **reddito**, correggendo il bias che potrebbe derivare dalla presenza di un **confonditore non osservato** (in questo caso, l'abilità). L'idea è che la variabile strumentale, cioè la **distanza al college**, influisca sull'istruzione, ma non direttamente sul reddito, consentendo di isolare l'effetto dell'istruzione sul reddito.\n",
    "\n",
    "Vediamo il codice passo per passo:\n",
    "\n",
    "### 1. **Generazione dei dati simulati**\n",
    "- **`ability`**: Un \"confonditore non osservato\" che rappresenta l'abilità di una persona, che influisce sia sull'istruzione che sul reddito. Viene generato come una variabile casuale normale con una media di 100 e deviazione standard di 15.\n",
    "  \n",
    "- **`distance_to_college`**: La distanza dal college più vicino (in chilometri), che viene generata come una variabile casuale con una distribuzione gamma. Questo è il nostro **strumento** (Instrumental Variable, IV), che influenza l'istruzione, ma **non** il reddito direttamente (è un'ipotesi cruciale per l'uso degli strumenti).\n",
    "\n",
    "- **`education`**: Gli anni di istruzione sono influenzati dalla distanza al college (una relazione negativa: più lontano è il college, meno istruzione una persona tende ad avere) e dall'abilità (più alta l'abilità, maggiore probabilità di ottenere più anni di istruzione). Inoltre, c'è un errore casuale. La funzione `np.maximum(education, 8)` garantisce che ogni persona abbia almeno 8 anni di istruzione.\n",
    "\n",
    "- **`earnings`**: Il reddito è influenzato dagli anni di istruzione e dall'abilità. La relazione con l'istruzione è tale che per ogni anno in più di istruzione, il reddito aumenta di 3000 unità. La relazione con l'abilità è più debole, con un aumento di 200 unità per ogni incremento dell'abilità.\n",
    "\n",
    "### 2. **Creazione del DataFrame**\n",
    "Il codice crea un dataframe chiamato `iv_data` che contiene tutte le variabili generato:\n",
    "- `Distance_to_College`: la distanza dal college.\n",
    "- `Education_Years`: gli anni di istruzione.\n",
    "- `Earnings`: il reddito.\n",
    "- `Ability`: l'abilità (che sarebbe un confonditore, quindi non disponibile nei dati reali, ma incluso qui per simulare la situazione).\n",
    "\n",
    "### 3. **Regressione naiva (biased)**\n",
    "Il codice esegue una **regressione lineare semplice** per stimare l'effetto dell'istruzione sul reddito:\n",
    "```python\n",
    "X = sm.add_constant(iv_data['Education_Years'])\n",
    "model = sm.OLS(iv_data['Earnings'], X).fit()\n",
    "```\n",
    "Questa regressione è **distorta** (biased) perché non tiene conto del confonditore `ability`. In pratica, l'abilità influisce sia sull'istruzione che sul reddito, quindi la stima dell'effetto dell'istruzione potrebbe essere falsata. Questo è un **bias da variabili omesse**.\n",
    "\n",
    "Il risultato mostra l'effetto stimato dell'istruzione sul reddito, ma questa stima potrebbe non essere accurata a causa del confondimento.\n",
    "\n",
    "### 4. **Stima con Variabili Strumentali (IV)**\n",
    "Per correggere il bias, il codice utilizza il metodo delle **due fasi dei minimi quadrati (2SLS)**, che sfrutta la variabile strumentale (`distance_to_college`) per isolare l'effetto causale dell'istruzione sul reddito.\n",
    "\n",
    "#### **Prima fase: Regressione dell'istruzione sulla variabile strumentale**\n",
    "In questa fase, si regredisce l'istruzione sulla distanza al college:\n",
    "```python\n",
    "X_first = sm.add_constant(iv_data['Distance_to_College'])\n",
    "first_stage = sm.OLS(iv_data['Education_Years'], X_first).fit()\n",
    "iv_data['Predicted_Education'] = first_stage.predict(X_first)\n",
    "```\n",
    "Qui, si utilizza la **distanza al college** come strumento per prevedere gli **anni di istruzione**. La previsione (`Predicted_Education`) è la stima dell'istruzione, che è influenzata dalla variabile strumentale, ma non direttamente dal confonditore `ability`.\n",
    "\n",
    "#### **Seconda fase: Regressione del reddito sulla prevedibile istruzione**\n",
    "Nella seconda fase, si regredisce il reddito sugli **anni di istruzione previsti** (cioè, quelli che non sono influenzati dall'abilità):\n",
    "```python\n",
    "X_second = sm.add_constant(iv_data['Predicted_Education'])\n",
    "second_stage = sm.OLS(iv_data['Earnings'], X_second).fit()\n",
    "```\n",
    "In questa fase, si stima l'effetto causale dell'istruzione sul reddito usando i valori predetti di `education` (quelli basati sulla variabile strumentale, non direttamente sull'abilità).\n",
    "\n",
    "### 5. **Risultato finale**\n",
    "Infine, il codice stampa i risultati di entrambe le stime:\n",
    "1. **Stima naive**: L'effetto dell'istruzione sul reddito basato sulla regressione semplice, che potrebbe essere distorto dal confonditore.\n",
    "2. **Stima con IV**: L'effetto causale stimato utilizzando il metodo delle variabili strumentali, che si avvicina al **vero effetto causale** dell'istruzione sul reddito.\n",
    "\n",
    "### **Risultati finali e interpretazione**\n",
    "- **Naive regression** (bias): La regressione semplice stima l'effetto dell'istruzione sul reddito, ma senza correggere per il confondimento dovuto all'abilità.\n",
    "  \n",
    "  - Il risultato stimato dall'OLS (la regressione semplice) è un ritorno all'istruzione di un certo valore per ogni anno di educazione.\n",
    "\n",
    "- **Stima con IV**: La stima usando **variabili strumentali** (2SLS) è più accurata, poiché corregge il bias causato dalla presenza dell'abilità, che è un confonditore.\n",
    "\n",
    "- **True effect**: L'effetto vero del trattamento (istruzione) sul reddito, nel modello simulato, è di 3000 $ per ogni anno aggiuntivo di istruzione.\n",
    "\n",
    "### **Conclusione**\n",
    "La tecnica delle **variabili strumentali** permette di ottenere una stima dell'effetto causale in presenza di confonditori non osservati. In questo caso, la distanza al college è utilizzata come strumento per correggere il bias da confondimento (abilità), portando a una stima dell'effetto causale dell'istruzione sul reddito più accurata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9948ccdb-0888-4b2b-851b-bc742880c31a",
   "metadata": {},
   "source": [
    "## 7. Scoperta causale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d04f65-251c-4dc3-aba7-f8b1d2d99cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between X and Z: 0.834\n",
      "Partial correlation between X and Z given Y: -0.090\n",
      "Near-zero partial correlation suggests that X and Z are conditionally independent given Y\n",
      "This supports the causal structure: X → Y → Z\n"
     ]
    }
   ],
   "source": [
    "# Esempio semplice di scoperta causale\n",
    "# Genera dati da una struttura causale nota: X → Y → Z\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "X = np.random.normal(0, 1, n)\n",
    "Y = 2*X + np.random.normal(0, 1, n)  # Y dipende da X\n",
    "Z = 1.5*Y + np.random.normal(0, 1, n)  # Z dipende da Y\n",
    "\n",
    "discovery_data = pd.DataFrame({'X': X, 'Y': Y, 'Z': Z})\n",
    "\n",
    "# Calcola l'indipendenza condizionale\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Correlazione tra X e Z\n",
    "corr_xz, _ = pearsonr(X, Z)\n",
    "print(f\"Correlation between X and Z: {corr_xz:.3f}\")\n",
    "\n",
    "# Correlazione parziale (X e Z dato Y)\n",
    "# Per prima cosa, ottieni i residui dalla regressione di X su Y\n",
    "X_resid = sm.OLS(X, sm.add_constant(Y)).fit().resid\n",
    "# Quindi, ottenere i residui dalla regressione di Z su Y\n",
    "Z_resid = sm.OLS(Z, sm.add_constant(Y)).fit().resid\n",
    "# Calcola la correlazione tra i residui\n",
    "partial_corr, _ = pearsonr(X_resid, Z_resid)\n",
    "\n",
    "print(f\"Partial correlation between X and Z given Y: {partial_corr:.3f}\")\n",
    "print(\"Near-zero partial correlation suggests that X and Z are conditionally independent given Y\")\n",
    "print(\"This supports the causal structure: X → Y → Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d506b-3dd3-4b0b-a57f-596c873f870c",
   "metadata": {},
   "source": [
    "Certo, ti spiegherò passo per passo il codice e come viene utilizzata l'analisi della **correlazione parziale** per supportare una struttura causale.\n",
    "\n",
    "### Obiettivo:\n",
    "Il codice vuole generare un dataset da una struttura causale nota \\( X \\rightarrow Y \\rightarrow Z \\) e testare se le relazioni tra le variabili possono supportare questa struttura causale. In altre parole, si vuole testare se \\( X \\) ha un effetto diretto su \\( Z \\), oppure se l'effetto di \\( X \\) su \\( Z \\) è mediato attraverso \\( Y \\).\n",
    "\n",
    "### Passo 1: Generare i dati\n",
    "Il codice inizia con la generazione di dati per le variabili \\( X \\), \\( Y \\) e \\( Z \\) in base alla struttura causale che si vuole modellare:\n",
    "\n",
    "1. **Generare \\( X \\)**: \\( X \\) è una variabile casuale che segue una distribuzione normale standard con media 0 e deviazione standard 1. È la variabile di partenza (causale).\n",
    "   ```python\n",
    "   X = np.random.normal(0, 1, n)\n",
    "   ```\n",
    "\n",
    "2. **Generare \\( Y \\)**: \\( Y \\) dipende direttamente da \\( X \\), in particolare \\( Y = 2X + \\epsilon \\), dove \\( \\epsilon \\) è un errore casuale che segue una distribuzione normale.\n",
    "   ```python\n",
    "   Y = 2*X + np.random.normal(0, 1, n)\n",
    "   ```\n",
    "\n",
    "3. **Generare \\( Z \\)**: \\( Z \\) dipende direttamente da \\( Y \\), cioè \\( Z = 1.5Y + \\epsilon \\), dove \\( \\epsilon \\) è un altro errore casuale.\n",
    "   ```python\n",
    "   Z = 1.5*Y + np.random.normal(0, 1, n)\n",
    "   ```\n",
    "\n",
    "In sintesi, \\( X \\) causa \\( Y \\), e \\( Y \\) causa \\( Z \\), quindi la struttura causale è \\( X \\rightarrow Y \\rightarrow Z \\).\n",
    "\n",
    "### Passo 2: Calcolare la **correlazione** tra \\( X \\) e \\( Z \\)\n",
    "La correlazione tra \\( X \\) e \\( Z \\) è calcolata usando la funzione `pearsonr`, che misura la forza e la direzione di una relazione lineare tra due variabili. In questo caso, senza considerare la variabile \\( Y \\), calcoliamo quanto sono correlati \\( X \\) e \\( Z \\).\n",
    "\n",
    "```python\n",
    "corr_xz, _ = pearsonr(X, Z)\n",
    "print(f\"Correlation between X and Z: {corr_xz:.3f}\")\n",
    "```\n",
    "\n",
    "Poiché \\( Y \\) è nel mezzo tra \\( X \\) e \\( Z \\), ci si aspetta una certa correlazione tra \\( X \\) e \\( Z \\), ma la presenza di \\( Y \\) potrebbe influenzare questa correlazione.\n",
    "\n",
    "### Passo 3: Calcolare la **correlazione parziale** tra \\( X \\) e \\( Z \\) dato \\( Y \\)\n",
    "Ora, vogliamo controllare se la correlazione tra \\( X \\) e \\( Z \\) è dovuta solo a \\( Y \\). Per fare ciò, calcoliamo la **correlazione parziale**, che misura la relazione tra due variabili mentre si controlla l'effetto di una terza variabile (in questo caso \\( Y \\)).\n",
    "\n",
    "#### Correlazione parziale: 2 fasi\n",
    "1. **Residui di \\( X \\) dato \\( Y \\)**:\n",
    "   - Prima, eseguiamo una regressione lineare di \\( X \\) su \\( Y \\) per vedere quanto di \\( X \\) è spiegato da \\( Y \\). I residui di questa regressione rappresentano la parte di \\( X \\) che **non è spiegata da \\( Y \\)**.\n",
    "   ```python\n",
    "   X_resid = sm.OLS(X, sm.add_constant(Y)).fit().resid\n",
    "   ```\n",
    "\n",
    "2. **Residui di \\( Z \\) dato \\( Y \\)**:\n",
    "   - Allo stesso modo, eseguiamo una regressione lineare di \\( Z \\) su \\( Y \\) per vedere quanto di \\( Z \\) è spiegato da \\( Y \\). I residui di questa regressione rappresentano la parte di \\( Z \\) che **non è spiegata da \\( Y \\)**.\n",
    "   ```python\n",
    "   Z_resid = sm.OLS(Z, sm.add_constant(Y)).fit().resid\n",
    "   ```\n",
    "\n",
    "3. **Calcolare la correlazione tra i residui**:\n",
    "   - Ora possiamo calcolare la correlazione tra i residui di \\( X \\) e \\( Z \\). Questo ci mostra quanto \\( X \\) e \\( Z \\) sono correlati **indipendentemente da \\( Y \\)**. Se questa correlazione è vicina a zero, significa che, dato \\( Y \\), non c'è più alcuna relazione diretta tra \\( X \\) e \\( Z \\).\n",
    "   ```python\n",
    "   partial_corr, _ = pearsonr(X_resid, Z_resid)\n",
    "   ```\n",
    "\n",
    "### Passo 4: Interpretazione\n",
    "Infine, il codice stampa la correlazione parziale tra \\( X \\) e \\( Z \\) dato \\( Y \\) e interpreta i risultati.\n",
    "\n",
    "```python\n",
    "print(f\"Partial correlation between X and Z given Y: {partial_corr:.3f}\")\n",
    "print(\"Near-zero partial correlation suggests that X and Z are conditionally independent given Y\")\n",
    "print(\"This supports the causal structure: X → Y → Z\")\n",
    "```\n",
    "\n",
    "- Se la **correlazione parziale** è **vicina a zero**, significa che \\( X \\) e \\( Z \\) sono **indipendenti** una volta che abbiamo controllato l'effetto di \\( Y \\). Questo suggerisce che la relazione tra \\( X \\) e \\( Z \\) è mediata da \\( Y \\), supportando la struttura causale \\( X \\rightarrow Y \\rightarrow Z \\).\n",
    "\n",
    "### Riepilogo:\n",
    "- **Correlazione diretta** tra \\( X \\) e \\( Z \\) potrebbe esserci, ma non è la relazione causale vera e propria (poiché \\( Y \\) è nel mezzo).\n",
    "- La **correlazione parziale** tra \\( X \\) e \\( Z \\) dato \\( Y \\) dovrebbe essere vicina a zero, indicando che, una volta che si controlla \\( Y \\), non c'è una relazione diretta tra \\( X \\) e \\( Z \\).\n",
    "  \n",
    "In conclusione, la struttura causale \\( X \\rightarrow Y \\rightarrow Z \\) è supportata dal fatto che la correlazione parziale tra \\( X \\) e \\( Z \\) dato \\( Y \\) è quasi nulla."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.env)",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

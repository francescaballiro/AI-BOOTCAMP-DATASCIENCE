{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riccardo Lorenzon - Head of Data @Vedrai \n",
    "\n",
    "riccardo.lorenzon@vedrai.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning Models\n",
    "\n",
    "## What is a Machine Learning model?\n",
    "\n",
    "$y = f(x)$ is the most general form of mathematical relationship between an input $x$ and an output $y$. We call our approximation of $f$ an Estimator\n",
    "\n",
    "We want to estimate $f$ in \"the most accurate way\" starting from available data thanks to a model which \"learns\" the underlying mathematical relationship (fit).\n",
    "\n",
    "Knowledge of $f$ is mainly used for prediction of $y$ for a specific $x$ which we have not seen in the orginal dataset (predict).\n",
    "\n",
    "## Regression or classification?\n",
    "\n",
    "We talk about **regression** when $y$ is a real value or vector. \n",
    "\n",
    "We talk about **classification** when $y$ is a categorical value or vector.\n",
    "\n",
    "## What is Linear Regression?\n",
    "\n",
    "Linear regression is one of the simplest and most commonly used machine learning algorithms. It tries to find a straight line that best fits your data, which can then be used to make predictions. \n",
    "\n",
    "$y = a + b*x$\n",
    "\n",
    "\n",
    "# Introduzione ai modelli di apprendimento automatico\n",
    "\n",
    "## Cos'è un modello di apprendimento automatico?\n",
    "\n",
    "$y = f(x)$ è la forma più generale di relazione matematica tra un input $x$ e un output $y$. Chiamiamo la nostra approssimazione di $f$ uno stimatore\n",
    "\n",
    "Vogliamo stimare $f$ nel \"modo più accurato\" partendo dai dati disponibili grazie a un modello che \"apprende\" la relazione matematica sottostante (adattamento).\n",
    "\n",
    "La conoscenza di $f$ è utilizzata principalmente per la previsione di $y$ per uno specifico $x$ che non abbiamo visto nel set di dati originale (previsione).\n",
    "\n",
    "## Regressione o classificazione?\n",
    "\n",
    "Parliamo di **regressione** quando $y$ è un valore reale o un vettore.\n",
    "\n",
    "Parliamo di **classificazione** quando $y$ è un valore categoriale o un vettore.\n",
    "\n",
    "## Cos'è la regressione lineare?\n",
    "\n",
    "La regressione lineare è uno degli algoritmi di apprendimento automatico più semplici e più comunemente utilizzati. Cerca di trovare una linea retta che si adatti meglio ai tuoi dati, che può poi essere usata per fare previsioni.\n",
    "\n",
    "$y = a + b*x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries\n",
    "\n",
    "First, we need to import the Python libraries that will help us work with data and build our model.\n",
    "\n",
    "## Passaggio 1: importare le librerie necessarie\n",
    "\n",
    "Per prima cosa, dobbiamo importare le librerie Python che ci aiuteranno a lavorare con i dati e a creare il nostro modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\franc\\pycharmprojects\\datascience\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\franc\\pycharmprojects\\datascience\\.venv\\lib\\site-packages (from scikit-learn) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\franc\\pycharmprojects\\datascience\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\franc\\pycharmprojects\\datascience\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\franc\\pycharmprojects\\datascience\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create or load a dataset\n",
    "\n",
    "For this tutorial, we'll create a simple dataset about house sizes and prices. In real projects, you would typically load data from a file or database (in our case titanic.csv).\n",
    "\n",
    "## Passaggio 2: creare o caricare un set di dati\n",
    "\n",
    "Per questo tutorial, creeremo un semplice set di dati sulle dimensioni e i prezzi delle case. Nei progetti reali, solitamente caricheresti i dati da un file o da un database (nel nostro caso titanic.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2126</td>\n",
       "      <td>394.191759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2459</td>\n",
       "      <td>311.021124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1860</td>\n",
       "      <td>357.228406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2294</td>\n",
       "      <td>418.782549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2130</td>\n",
       "      <td>463.787702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Size       Price\n",
       "0  2126  394.191759\n",
       "1  2459  311.021124\n",
       "2  1860  357.228406\n",
       "3  2294  418.782549\n",
       "4  2130  463.787702"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample dataset (house size in square feet and price in thousands of dollars)\n",
    "np.random.seed(42)  # For reproducible results\n",
    "n_samples = 200\n",
    "\n",
    "# House sizes between 1000 and 3000 square feet\n",
    "house_sizes = np.random.randint(1000, 3000, n_samples)\n",
    "\n",
    "# House prices with some relationship to size plus random noise\n",
    "house_prices = 100 + 0.2 * house_sizes - 0.00003 * house_sizes**2 + np.random.normal(0, 50, n_samples)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Size': house_sizes,\n",
    "    'Price': house_prices\n",
    "})\n",
    "\n",
    "# Display the first 5 rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Or we load our most beloved dataset (maybe we use it later)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m titanic \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitanic.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m titanic\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\PycharmProjects\\DataScience\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\DataScience\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\PycharmProjects\\DataScience\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\DataScience\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\PycharmProjects\\DataScience\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic.csv'"
     ]
    }
   ],
   "source": [
    "# Or we load our most beloved dataset (maybe we use it later)\n",
    "\n",
    "titanic = pd.read_csv('titanic.csv')\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize the data\n",
    "\n",
    "It's important to visualize your data to understand the relationship between variables before building a model.\n",
    "\n",
    "## Passaggio 3: visualizzare i dati\n",
    "\n",
    "È importante visualizzare i dati per comprendere la relazione tra le variabili prima di creare un modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of house size vs. price\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['Size'], data['Price'])\n",
    "plt.title('House Size vs. Price')\n",
    "plt.xlabel('House Size (square feet)')\n",
    "plt.ylabel('House Price (thousands of dollars)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Simpson's Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split the data into training and testing sets\n",
    "\n",
    "Before training our model, we need to split our data into:\n",
    "- **Training set**: Used to train the model\n",
    "- **Testing set**: Used to evaluate how well the model performs on new, unseen data\n",
    "\n",
    "Why?\n",
    "\n",
    "We need to ensure our model **generalizes** enough, meaning it does not learn the specific structure of the training set, but rather learns the underlying structure of $f$\n",
    "\n",
    "## Passaggio 4: suddividere i dati in set di training e test\n",
    "\n",
    "Prima di addestrare il nostro modello, dobbiamo suddividere i nostri dati in:\n",
    "- **Set di training**: utilizzato per addestrare il modello\n",
    "- **Set di test**: utilizzato per valutare le prestazioni del modello su dati nuovi e inediti\n",
    "\n",
    "Perché?\n",
    "\n",
    "Dobbiamo assicurarci che il nostro modello **generalizzi** a sufficienza, ovvero che non apprenda la struttura specifica del set di training, ma piuttosto apprenda la struttura sottostante di $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data[['Size']]  # Features (input)\n",
    "y = data['Price']   # Target (output)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing data size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create and train the model\n",
    "\n",
    "Now we'll create a linear regression model and train it using our training data.\n",
    "\n",
    "\n",
    "## Passaggio 5: creare e addestrare il modello\n",
    "\n",
    "Ora creeremo un modello di regressione lineare e lo addestreremo utilizzando i nostri dati di addestramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Check the coefficient (slope) and intercept of our linear model\n",
    "print(f\"Model coefficient (slope): {model.coef_[0]:.4f}\")\n",
    "print(f\"Model intercept: {model.intercept_:.4f}\")\n",
    "print(f\"y = {model.intercept_:.4f} + {model.coef_[0]:.4f} * x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Make predictions and evaluate the model\n",
    "\n",
    "Let's use our trained model to make predictions on the test data and evaluate how well it performs.\n",
    "\n",
    "## Fase 6: fare previsioni e valutare il modello\n",
    "\n",
    "Utilizziamo il nostro modello addestrato per fare previsioni sui dati di test e valutare le sue prestazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error (MSE) - a common metric to evaluate regression models\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "# Calculate R-squared score (coefficient of determination)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize the results\n",
    "\n",
    "Finally, let's visualize our model's predictions against the actual data to see how well our linear regression line fits.\n",
    "\n",
    "## Passaggio 7: visualizza i risultati\n",
    "\n",
    "Infine, visualizziamo le previsioni del nostro modello rispetto ai dati effettivi per vedere quanto bene si adatta la nostra linea di regressione lineare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original data points\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test, y_test, color='blue', label='Actual Prices')\n",
    "\n",
    "# Plot the predicted data points\n",
    "plt.scatter(X_test, y_pred, color='red', label='Predicted Prices')\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(X_test, y_pred, color='green', linewidth=2, label='Regression Line')\n",
    "\n",
    "plt.title('House Price Prediction (Test Data)')\n",
    "plt.xlabel('House Size (square feet)')\n",
    "plt.ylabel('House Price (thousands of dollars)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Use the model to make new predictions\n",
    "\n",
    "Now that we have a trained model, we can use it to predict the price of houses with sizes that weren't in our original dataset.\n",
    "\n",
    "## Passaggio 8: utilizzare il modello per fare nuove previsioni\n",
    "\n",
    "Ora che abbiamo un modello addestrato, possiamo utilizzarlo per prevedere il prezzo delle case con dimensioni che non erano nel nostro set di dati originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some new house sizes that we want to predict prices for\n",
    "new_house_sizes = np.array([[1500], [2000], [2500]])\n",
    "\n",
    "# Use our model to predict the prices\n",
    "predicted_prices = model.predict(new_house_sizes)\n",
    "\n",
    "# Display the results\n",
    "for size, price in zip(new_house_sizes.flatten(), predicted_prices):\n",
    "    print(f\"A house with {size} square feet is predicted to cost ${price:.2f} thousand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are Overfitting and Underfitting?\n",
    "\n",
    "When training machine learning models, we face two common challenges:\n",
    "\n",
    "1. **Underfitting**: The model is too simple and fails to capture the underlying pattern in the data.\n",
    "2. **Overfitting**: The model is too complex and fits the training data too closely, capturing noise instead of the true underlying relationship.\n",
    "\n",
    "Let's visualize these concepts using our house price dataset\n",
    "\n",
    "### Cosa sono l'overfitting e l'underfitting?\n",
    "\n",
    "Quando si addestrano modelli di apprendimento automatico, ci troviamo di fronte a due sfide comuni:\n",
    "\n",
    "1. **Underfitting**: il modello è troppo semplice e non riesce a catturare il pattern sottostante nei dati.\n",
    "2. **Overfitting**: il modello è troppo complesso e si adatta troppo da vicino ai dati di addestramento, catturando il rumore invece della vera relazione sottostante.\n",
    "\n",
    "Visualizziamo questi concetti utilizzando il nostro set di dati sui prezzi delle case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = data[['Size']]\n",
    "y = data['Price']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create models of varying complexity\n",
    "models = [\n",
    "    ('Underfit (Linear)', LinearRegression()),\n",
    "    ('Just Right (Quadratic)', make_pipeline(PolynomialFeatures(2), LinearRegression())),\n",
    "    ('Overfit (High Degree Polynomial)', make_pipeline(PolynomialFeatures(10), LinearRegression()))\n",
    "]\n",
    "\n",
    "# Visualize different model complexities\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, (name, model) in enumerate(models, 1):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate errors\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(1, 3, i)\n",
    "    \n",
    "    # Sort X for smooth curve plotting\n",
    "    sort_axis = np.argsort(X_test.values.flatten())\n",
    "    X_test_sorted = X_test.values[sort_axis]\n",
    "    y_test_sorted = y_test.values[sort_axis]\n",
    "    y_pred_sorted = y_test_pred[sort_axis]\n",
    "    \n",
    "    # Scatter plot of actual data\n",
    "    plt.scatter(X_test, y_test, color='blue', alpha=0.5, label='Actual Data')\n",
    "    \n",
    "    # Plot the model's predictions\n",
    "    plt.plot(X_test_sorted, y_pred_sorted, color='red', label='Model Prediction')\n",
    "    \n",
    "    plt.title(f'{name}\\nTrain MSE: {train_mse:.2f}\\nTest MSE: {test_mse:.2f}')\n",
    "    plt.xlabel('House Size')\n",
    "    plt.ylabel('House Price')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus during the lesson in case of available time\n",
    "\n",
    "Implement classification on titanic dataset with sklearn NaiveBayesClassifier or LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've just built and trained your first machine learning model using linear regression. Here's what we learned:\n",
    "\n",
    "1. How to prepare and visualize data\n",
    "2. How to split data into training and testing sets\n",
    "3. How to create and train a linear regression model\n",
    "4. How to evaluate the model's performance\n",
    "5. How to use the model to make new predictions\n",
    "6. How to qualitatively assess if we are overfitting or underfitting\n",
    "\n",
    "This is just the beginning of your machine learning journey. As you progress, you can explore more complex algorithms and datasets!\n",
    "\n",
    "## Conclusione\n",
    "\n",
    "Congratulazioni! Hai appena creato e addestrato il tuo primo modello di apprendimento automatico utilizzando la regressione lineare. Ecco cosa abbiamo imparato:\n",
    "\n",
    "1. Come preparare e visualizzare i dati\n",
    "2. Come suddividere i dati in set di addestramento e test\n",
    "3. Come creare e addestrare un modello di regressione lineare\n",
    "4. Come valutare le prestazioni del modello\n",
    "5. Come utilizzare il modello per fare nuove previsioni\n",
    "6. Come valutare qualitativamente se stiamo eseguendo un overfitting o un underfitting\n",
    "\n",
    "Questo è solo l'inizio del tuo viaggio di apprendimento automatico. Man mano che procedi, puoi esplorare algoritmi e set di dati più complessi!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Exercise\n",
    "\n",
    "Start from this notebook.\n",
    "\n",
    "Assume house price depends not only on size, but also on number of windows.\n",
    "\n",
    "n_windows = np.random.randint(3,8,100)\n",
    "\n",
    "house_prices = 100 + 0.2 * house_sizes - 0.00003 * house_sizes**2 + np.random.normal(0, 50, n_samples) + 15*n_windows\n",
    "\n",
    "Try:\n",
    "1) change the initial data, but keep using only house_sizes as regressor. What has changed?\n",
    "2) adapt the notebook to using both house_sizes and n_windows as regressors. What has changed?\n",
    "3) come up with a good way to visualize linear regression outputs with 2 regressors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
